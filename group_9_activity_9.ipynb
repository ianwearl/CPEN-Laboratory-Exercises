{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMKdkyqIDZ/RUJdhFLf27G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ianwearl/CPEN-Laboratory-Exercises/blob/main/group_9_activity_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Laboratory Exercise 9: Deep Computer Vision Using Convolutional Neural Networks"
      ],
      "metadata": {
        "id": "Qv1gTCpIJQ1q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCJehYhLJMbF",
        "outputId": "65c572a4-22f3-4001-d277-0e71989df99d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU was detected. CNNs can be very slow without a GPU.\n",
            "Go to Runtime > Change runtime and select a GPU hardware accelerator.\n"
          ]
        }
      ],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Is this notebook running on Colab or Kaggle?\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "    if IS_KAGGLE:\n",
        "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"cnn\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image(image):\n",
        "    plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "def plot_color_image(image):\n",
        "    plt.imshow(image, interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "mHrPlVkNJXgA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "X_train_full = X_train_full / 255.\n",
        "X_test = X_test / 255.\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
        "\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_valid = X_valid[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ULsmk8oJbaq",
        "outputId": "e4f7a6e1-4b1c-4c16-b9ee-fc51d203d24f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    keras.layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    keras.layers.MaxPool2D(),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqwzHQCXJdHs",
        "outputId": "e5c71149-dce8-4287-9e2c-31e4791642c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 265s 153ms/step - loss: 0.1938 - accuracy: 0.9405 - val_loss: 0.0409 - val_accuracy: 0.9884\n",
            "Epoch 2/10\n",
            " 653/1719 [==========>...................] - ETA: 2:32 - loss: 0.0830 - accuracy: 0.9738"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Is this notebook running on Colab or Kaggle?\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "    if IS_KAGGLE:\n",
        "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"cnn\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "metadata": {
        "id": "JbOPlFyLJfZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image(image):\n",
        "    plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "def plot_color_image(image):\n",
        "    plt.imshow(image, interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "9k3yU2KvJo2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "dataset, info = tfds.load(\"tf_flowers\", as_supervised=True, with_info=True)"
      ],
      "metadata": {
        "id": "dmkyH6cVJr3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info.splits"
      ],
      "metadata": {
        "id": "62ASL2YSJtpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info.splits[\"train\"]"
      ],
      "metadata": {
        "id": "u9PAWMmCJvnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = info.features[\"label\"].names\n",
        "class_names"
      ],
      "metadata": {
        "id": "sN-uUchjJxYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = info.features[\"label\"].num_classes\n",
        "\n",
        "dataset_size = info.splits[\"train\"].num_examples\n",
        "dataset_size"
      ],
      "metadata": {
        "id": "tUvvs3XuJ0sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set_raw, valid_set_raw, train_set_raw = tfds.load(\n",
        "    \"tf_flowers\",\n",
        "    split=[\"train[:10%]\", \"train[10%:25%]\", \"train[25%:]\"],\n",
        "    as_supervised=True)"
      ],
      "metadata": {
        "id": "H1apOYvNJ2Ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 10))\n",
        "index = 0\n",
        "for image, label in train_set_raw.take(9):\n",
        "    index += 1\n",
        "    plt.subplot(3, 3, index)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Class: {}\".format(class_names[label]))\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RL2acKo0J3uA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(image, label):\n",
        "    resized_image = tf.image.resize(image, [224, 224])\n",
        "    final_image = keras.applications.xception.preprocess_input(resized_image)\n",
        "    return final_image, label"
      ],
      "metadata": {
        "id": "EflBtqjrJ6fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "\n",
        "def central_crop(image):\n",
        "    shape = tf.shape(image)\n",
        "    min_dim = tf.reduce_min([shape[0], shape[1]])\n",
        "    top_crop = (shape[0] - min_dim) // 4\n",
        "    bottom_crop = shape[0] - top_crop\n",
        "    left_crop = (shape[1] - min_dim) // 4\n",
        "    right_crop = shape[1] - left_crop\n",
        "    return image[top_crop:bottom_crop, left_crop:right_crop]\n",
        "\n",
        "def random_crop(image):\n",
        "    shape = tf.shape(image)\n",
        "    min_dim = tf.reduce_min([shape[0], shape[1]]) * 90 // 100\n",
        "    return tf.image.random_crop(image, [min_dim, min_dim, 3])\n",
        "\n",
        "def preprocess(image, label, randomize=False):\n",
        "    if randomize:\n",
        "        cropped_image = random_crop(image)\n",
        "        cropped_image = tf.image.random_flip_left_right(cropped_image)\n",
        "    else:\n",
        "        cropped_image = central_crop(image)\n",
        "    resized_image = tf.image.resize(cropped_image, [224, 224])\n",
        "    final_image = keras.applications.xception.preprocess_input(resized_image)\n",
        "    return final_image, label\n",
        "\n",
        "batch_size = 32\n",
        "train_set = train_set_raw.shuffle(1000).repeat()\n",
        "train_set = train_set.map(functools.partial(preprocess, randomize=True)).batch(batch_size).prefetch(1)\n",
        "valid_set = valid_set_raw.map(preprocess).batch(batch_size).prefetch(1)\n",
        "test_set = test_set_raw.map(preprocess).batch(batch_size).prefetch(1)"
      ],
      "metadata": {
        "id": "__z-KI6PJ97D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "for X_batch, y_batch in train_set.take(1):\n",
        "    for index in range(9):\n",
        "        plt.subplot(3, 3, index + 1)\n",
        "        plt.imshow(X_batch[index] / 2 + 0.5)\n",
        "        plt.title(\"Class: {}\".format(class_names[y_batch[index]]))\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r4Ody-OaJ_8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "for X_batch, y_batch in test_set.take(1):\n",
        "    for index in range(9):\n",
        "        plt.subplot(3, 3, index + 1)\n",
        "        plt.imshow(X_batch[index] / 2 + 0.5)\n",
        "        plt.title(\"Class: {}\".format(class_names[y_batch[index]]))\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JR2UaAjtKC1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = keras.applications.xception.Xception(weights=\"imagenet\",\n",
        "                                                  include_top=False)\n",
        "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "output = keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
        "model = keras.models.Model(inputs=base_model.input, outputs=output)\n",
        "for index, layer in enumerate(base_model.layers):\n",
        "    print(index, layer.name)"
      ],
      "metadata": {
        "id": "LQ0UyJu7KEZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "base_model = tf.keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.2, momentum=0.9, decay=0.01)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "dataset_size = len(train_images)\n",
        "batch_size = 128\n",
        "\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    steps_per_epoch=int(0.75 * dataset_size / batch_size),\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    validation_steps=int(0.15 * dataset_size / batch_size),\n",
        "                    epochs=5)\n"
      ],
      "metadata": {
        "id": "M7YHPHm9KRGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "ans26k3rKTqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib as mpl\n",
        "\n",
        "import IPython.display as display\n",
        "import PIL.Image"
      ],
      "metadata": {
        "id": "yoxtJ1z2KWcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg'"
      ],
      "metadata": {
        "id": "9xy9z3RpKZUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download an image and read it into a NumPy array.\n",
        "def download(url, max_dim=None):\n",
        "  name = url.split('/')[-1]\n",
        "  image_path = tf.keras.utils.get_file(name, origin=url)\n",
        "  img = PIL.Image.open(image_path)\n",
        "  if max_dim:\n",
        "    img.thumbnail((max_dim, max_dim))\n",
        "  return np.array(img)\n",
        "\n",
        "# Normalize an image\n",
        "def deprocess(img):\n",
        "  img = 255*(img + 1.0)/2.0\n",
        "  return tf.cast(img, tf.uint8)\n",
        "\n",
        "# Display an image\n",
        "def show(img):\n",
        "  display.display(PIL.Image.fromarray(np.array(img)))\n",
        "\n",
        "\n",
        "# Downsizing the image makes it easier to work with.\n",
        "original_img = download(url, max_dim=500)\n",
        "show(original_img)\n",
        "display.display(display.HTML('Image cc-by: <a \"href=https://commons.wikimedia.org/wiki/File:Felis_catus-cat_on_snow.jpg\">Von.grzanka</a>'))"
      ],
      "metadata": {
        "id": "_RWdJGNMKbW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')"
      ],
      "metadata": {
        "id": "5HZNBL11Kdf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Maximize the activations of these layers\n",
        "names = ['mixed3', 'mixed5']\n",
        "layers = [base_model.get_layer(name).output for name in names]\n",
        "\n",
        "# Create the feature extraction model\n",
        "dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)"
      ],
      "metadata": {
        "id": "3jqMo5TCKgMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss(img, model):\n",
        "  # Pass forward the image through the model to retrieve the activations.\n",
        "  # Converts the image into a batch of size 1.\n",
        "  img_batch = tf.expand_dims(img, axis=0)\n",
        "  layer_activations = model(img_batch)\n",
        "  if len(layer_activations) == 1:\n",
        "    layer_activations = [layer_activations]\n",
        "\n",
        "  losses = []\n",
        "  for act in layer_activations:\n",
        "    loss = tf.math.reduce_mean(act)\n",
        "    losses.append(loss)\n",
        "\n",
        "  return  tf.reduce_sum(losses)"
      ],
      "metadata": {
        "id": "jnpwXgtXKhkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepDream(tf.Module):\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "\n",
        "  @tf.function(\n",
        "      input_signature=(\n",
        "        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=[], dtype=tf.int32),\n",
        "        tf.TensorSpec(shape=[], dtype=tf.float32),)\n",
        "  )\n",
        "  def __call__(self, img, steps, step_size):\n",
        "      print(\"Tracing\")\n",
        "      loss = tf.constant(0.0)\n",
        "      for n in tf.range(steps):\n",
        "        with tf.GradientTape() as tape:\n",
        "          # This needs gradients relative to `img`\n",
        "          # `GradientTape` only watches `tf.Variable`s by default\n",
        "          tape.watch(img)\n",
        "          loss = calc_loss(img, self.model)\n",
        "\n",
        "        # Calculate the gradient of the loss with respect to the pixels of the input image.\n",
        "        gradients = tape.gradient(loss, img)\n",
        "\n",
        "        # Normalize the gradients.\n",
        "        gradients /= tf.math.reduce_std(gradients) + 1e-8\n",
        "\n",
        "        # In gradient ascent, the \"loss\" is maximized so that the input image increasingly \"excites\" the layers.\n",
        "        # You can update the image by directly adding the gradients (because they're the same shape!)\n",
        "        img = img + gradients*step_size\n",
        "        img = tf.clip_by_value(img, -1, 1)\n",
        "\n",
        "      return loss, img"
      ],
      "metadata": {
        "id": "OhA-2c17Ki2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deepdream = DeepDream(dream_model)"
      ],
      "metadata": {
        "id": "iporKuZXKlKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_deep_dream_simple(img, steps=100, step_size=0.01):\n",
        "  # Convert from uint8 to the range expected by the model.\n",
        "  img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "  img = tf.convert_to_tensor(img)\n",
        "  step_size = tf.convert_to_tensor(step_size)\n",
        "  steps_remaining = steps\n",
        "  step = 0\n",
        "  while steps_remaining:\n",
        "    if steps_remaining>100:\n",
        "      run_steps = tf.constant(100)\n",
        "    else:\n",
        "      run_steps = tf.constant(steps_remaining)\n",
        "    steps_remaining -= run_steps\n",
        "    step += run_steps\n",
        "\n",
        "    loss, img = deepdream(img, run_steps, tf.constant(step_size))\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    show(deprocess(img))\n",
        "    print (\"Step {}, loss {}\".format(step, loss))\n",
        "\n",
        "\n",
        "  result = deprocess(img)\n",
        "  display.clear_output(wait=True)\n",
        "  show(result)\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "Vo6xGvMzKoWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dream_img = run_deep_dream_simple(img=original_img,\n",
        "                                  steps=100, step_size=0.01)"
      ],
      "metadata": {
        "id": "13OFa4fgKpyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "OCTAVE_SCALE = 1.30\n",
        "\n",
        "img = tf.constant(np.array(original_img))\n",
        "base_shape = tf.shape(img)[:-1]\n",
        "float_base_shape = tf.cast(base_shape, tf.float32)\n",
        "\n",
        "for n in range(-2, 3):\n",
        "  new_shape = tf.cast(float_base_shape*(OCTAVE_SCALE**n), tf.int32)\n",
        "\n",
        "  img = tf.image.resize(img, new_shape).numpy()\n",
        "\n",
        "  img = run_deep_dream_simple(img=img, steps=50, step_size=0.01)\n",
        "\n",
        "display.clear_output(wait=True)\n",
        "img = tf.image.resize(img, base_shape)\n",
        "img = tf.image.convert_image_dtype(img/255.0, dtype=tf.uint8)\n",
        "show(img)\n",
        "\n",
        "end = time.time()\n",
        "end-start"
      ],
      "metadata": {
        "id": "765LkzpSKsg1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}